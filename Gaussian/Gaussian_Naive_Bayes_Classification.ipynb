{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/tumor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_data size -> (426, 33)\n",
      "Testing_data size -> (143, 33)\n"
     ]
    }
   ],
   "source": [
    "ind = list(data.index)\n",
    "np.random.shuffle(ind)\n",
    "\n",
    "train_len = int(data.shape[0]*0.75)\n",
    "train_ind = ind[:train_len]\n",
    "training_data = data.iloc[train_ind,:]\n",
    "#training_data.head()\n",
    "\n",
    "test_ind = ind[train_len:]\n",
    "testing_data = data.iloc[test_ind,:]\n",
    "#testing_data.head()\n",
    "\n",
    "print('Training_data size -> {}'.format(training_data.shape))\n",
    "print('Testing_data size -> {}'.format(testing_data.shape))\n",
    "\n",
    "assert data.shape[0] ==  len(train_ind)+ len(test_ind), 'Not equal distribution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashank/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "training_data.drop(columns=[data.columns[0],data.columns[-1]], inplace=True)\n",
    "testing_data.drop(columns=[data.columns[0],data.columns[-1]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>M</td>\n",
       "      <td>21.16</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.08632</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>...</td>\n",
       "      <td>29.17</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>M</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.2088</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>M</td>\n",
       "      <td>17.46</td>\n",
       "      <td>39.28</td>\n",
       "      <td>113.40</td>\n",
       "      <td>920.6</td>\n",
       "      <td>0.09812</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.08811</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.51</td>\n",
       "      <td>44.87</td>\n",
       "      <td>141.20</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>0.13650</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.2853</td>\n",
       "      <td>0.08496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>B</td>\n",
       "      <td>14.26</td>\n",
       "      <td>19.65</td>\n",
       "      <td>97.83</td>\n",
       "      <td>629.9</td>\n",
       "      <td>0.07837</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.30030</td>\n",
       "      <td>0.07798</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>...</td>\n",
       "      <td>15.30</td>\n",
       "      <td>23.73</td>\n",
       "      <td>107.00</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0.08949</td>\n",
       "      <td>0.4193</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>0.1505</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.10820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>B</td>\n",
       "      <td>12.47</td>\n",
       "      <td>18.60</td>\n",
       "      <td>81.09</td>\n",
       "      <td>481.9</td>\n",
       "      <td>0.09965</td>\n",
       "      <td>0.1058</td>\n",
       "      <td>0.08005</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>...</td>\n",
       "      <td>14.97</td>\n",
       "      <td>24.64</td>\n",
       "      <td>96.05</td>\n",
       "      <td>677.9</td>\n",
       "      <td>0.14260</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.08750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "23          M        21.16         23.04          137.20     1404.0   \n",
       "47          M        13.17         18.66           85.98      534.6   \n",
       "239         M        17.46         39.28          113.40      920.6   \n",
       "112         B        14.26         19.65           97.83      629.9   \n",
       "204         B        12.47         18.60           81.09      481.9   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "23           0.09428            0.1022         0.10970              0.08632   \n",
       "47           0.11580            0.1231         0.12260              0.07340   \n",
       "239          0.09812            0.1298         0.14170              0.08811   \n",
       "112          0.07837            0.2233         0.30030              0.07798   \n",
       "204          0.09965            0.1058         0.08005              0.03821   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "23          0.1769  ...         29.17          35.59           188.00   \n",
       "47          0.2128  ...         15.67          27.95           102.80   \n",
       "239         0.1809  ...         22.51          44.87           141.20   \n",
       "112         0.1704  ...         15.30          23.73           107.00   \n",
       "204         0.1925  ...         14.97          24.64            96.05   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "23       2615.0           0.14010             0.2600           0.3155   \n",
       "47        759.4           0.17860             0.4166           0.5006   \n",
       "239      1408.0           0.13650             0.3735           0.3241   \n",
       "112       709.0           0.08949             0.4193           0.6783   \n",
       "204       677.9           0.14260             0.2378           0.2671   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "23                 0.2009          0.2822                  0.07526  \n",
       "47                 0.2088          0.3900                  0.11790  \n",
       "239                0.2066          0.2853                  0.08496  \n",
       "112                0.1505          0.2398                  0.10820  \n",
       "204                0.1015          0.3014                  0.08750  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>M</td>\n",
       "      <td>14.420</td>\n",
       "      <td>19.77</td>\n",
       "      <td>94.48</td>\n",
       "      <td>642.5</td>\n",
       "      <td>0.09752</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.09388</td>\n",
       "      <td>0.05839</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>...</td>\n",
       "      <td>16.330</td>\n",
       "      <td>30.86</td>\n",
       "      <td>109.50</td>\n",
       "      <td>826.4</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>0.31940</td>\n",
       "      <td>0.15650</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>0.09353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>M</td>\n",
       "      <td>16.260</td>\n",
       "      <td>21.88</td>\n",
       "      <td>107.50</td>\n",
       "      <td>826.8</td>\n",
       "      <td>0.11650</td>\n",
       "      <td>0.12830</td>\n",
       "      <td>0.17990</td>\n",
       "      <td>0.07981</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>...</td>\n",
       "      <td>17.730</td>\n",
       "      <td>25.21</td>\n",
       "      <td>113.70</td>\n",
       "      <td>975.2</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.33440</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.07953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>B</td>\n",
       "      <td>11.430</td>\n",
       "      <td>17.31</td>\n",
       "      <td>73.66</td>\n",
       "      <td>398.0</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.09486</td>\n",
       "      <td>0.02031</td>\n",
       "      <td>0.01861</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>...</td>\n",
       "      <td>12.780</td>\n",
       "      <td>26.76</td>\n",
       "      <td>82.66</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.07708</td>\n",
       "      <td>0.06402</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.08096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>B</td>\n",
       "      <td>14.440</td>\n",
       "      <td>15.18</td>\n",
       "      <td>93.97</td>\n",
       "      <td>640.1</td>\n",
       "      <td>0.09970</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.08487</td>\n",
       "      <td>0.05532</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>...</td>\n",
       "      <td>15.850</td>\n",
       "      <td>19.85</td>\n",
       "      <td>108.60</td>\n",
       "      <td>766.9</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.31030</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.2691</td>\n",
       "      <td>0.07683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>B</td>\n",
       "      <td>8.878</td>\n",
       "      <td>15.49</td>\n",
       "      <td>56.74</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.08293</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04721</td>\n",
       "      <td>0.02381</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>...</td>\n",
       "      <td>9.981</td>\n",
       "      <td>17.70</td>\n",
       "      <td>65.27</td>\n",
       "      <td>302.0</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.09441</td>\n",
       "      <td>0.04762</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.07431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "99          M       14.420         19.77           94.48      642.5   \n",
       "329         M       16.260         21.88          107.50      826.8   \n",
       "142         B       11.430         17.31           73.66      398.0   \n",
       "148         B       14.440         15.18           93.97      640.1   \n",
       "358         B        8.878         15.49           56.74      241.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "99           0.09752           0.11410         0.09388              0.05839   \n",
       "329          0.11650           0.12830         0.17990              0.07981   \n",
       "142          0.10920           0.09486         0.02031              0.01861   \n",
       "148          0.09970           0.10210         0.08487              0.05532   \n",
       "358          0.08293           0.07698         0.04721              0.02381   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "99          0.1879  ...        16.330          30.86           109.50   \n",
       "329         0.1869  ...        17.730          25.21           113.70   \n",
       "142         0.1645  ...        12.780          26.76            82.66   \n",
       "148         0.1724  ...        15.850          19.85           108.60   \n",
       "358         0.1930  ...         9.981          17.70            65.27   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "99        826.4            0.1431             0.3026          0.31940   \n",
       "329       975.2            0.1426             0.2116          0.33440   \n",
       "142       503.0            0.1413             0.1792          0.07708   \n",
       "148       766.9            0.1316             0.2735          0.31030   \n",
       "358       302.0            0.1015             0.1248          0.09441   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "99                0.15650          0.2718                  0.09353  \n",
       "329               0.10470          0.2736                  0.07953  \n",
       "142               0.06402          0.2584                  0.08096  \n",
       "148               0.15990          0.2691                  0.07683  \n",
       "358               0.04762          0.2434                  0.07431  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB:\n",
    "    def __init__(self, target, dataframe):\n",
    "        self.df = dataframe\n",
    "        # Target/Category Column\n",
    "        self.c_n = target\n",
    "        # Column Names\n",
    "        self.cols = list(self.df.columns)\n",
    "        self.cols.remove(self.c_n)\n",
    "        \n",
    "        # Determine Continuous or Discrete for each Columns\n",
    "        self.rv = {}\n",
    "        self.determine_rv_for_all()\n",
    "        \n",
    "        # Likelihoods of Discrete Random Variables\n",
    "        self.store = {}\n",
    "        self.discrete_likelihood_for_all()\n",
    "        \n",
    "        \n",
    "    def discrete_likelihood_cal(self, x, y, z):\n",
    "        \"\"\" \n",
    "        x -> Column Name (String)\n",
    "        y -> Column Value (String)\n",
    "        z -> Class value (String)\n",
    "        c_n -> Class Name (Target) # Not an Argument here #\n",
    "        \n",
    "        Returns -> P(x = y | c_n = z)\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        \n",
    "        if x not in self.cols:\n",
    "            raise KeyError(\"Feature(column) not present in the Training Dataset\")\n",
    "        \n",
    "        res = (1+len(df[(df[x] == y) & (df[self.c_n] == z)])) /(len(df[df[self.c_n] == z]) + len(df[x].unique()))\n",
    "        \n",
    "        \"\"\"if res == 0.0:\n",
    "            return 1/(len(df[df[self.c_n] == z]) + len(df[x].unique()))\"\"\"\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def discrete_likelihood_for_all(self):     \n",
    "        df = self.df\n",
    "        \n",
    "        discrete_cols = [x for x in self.cols if self.rv[x] == 'discrete']\n",
    "        \n",
    "        dict1 = {}\n",
    "        for x in discrete_cols:\n",
    "            dict2 = {}\n",
    "            for y in df[x].unique():\n",
    "                dict3 = {}\n",
    "                for z in df[self.c_n].unique():\n",
    "                    #print('P({}=\"{}\"|{}=\"{}\") = {}'.format(x,y,self.c_n,z,self.discrete_likelihood_cal(x, y, z)))\n",
    "                    dict3[z] = self.discrete_likelihood_cal(x, y, z)\n",
    "                dict2[y] = dict3\n",
    "            dict1[x] = dict2\n",
    "        \n",
    "        self.store = dict1\n",
    "        \n",
    "    def determine_rv(self, x):\n",
    "        \"\"\"\n",
    "        x -> Column Name\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        \n",
    "        val = list(df[x])[0]\n",
    "        \n",
    "        if type(val) == str or (type(val) == int and len(df[x].unique()) < len(df[x])):\n",
    "            return 'discrete'\n",
    "        return 'continuous'\n",
    "    \n",
    "    def determine_rv_for_all(self):\n",
    "        \"\"\"\n",
    "        self.rv = {}\n",
    "        \"\"\"\n",
    "        \n",
    "        self.rv = {x:self.determine_rv(x) for x in self.cols}\n",
    "\n",
    "    def normal_pdf(self, sample, x=None):\n",
    "        mu = np.mean(sample)\n",
    "        sigma = np.std(sample)\n",
    "        if x == None:\n",
    "            x = sample\n",
    "\n",
    "        expr = np.exp((-1/2)*(((x-mu)/sigma)**2))/(np.sqrt(2*np.pi*sigma))\n",
    "        return expr\n",
    "\n",
    "    def continuous_likelihood_cal(self, column_name, column_val, class_val):\n",
    "        df = self.df\n",
    "        \n",
    "        sample = df[df[self.c_n] == class_val][column_name]\n",
    "\n",
    "        return self.normal_pdf(sample, column_val)\n",
    "    \n",
    "    def likelihood_expr(self, class_val, expr):\n",
    "        val = 1  \n",
    "        \n",
    "        for k,v in expr:\n",
    "            \n",
    "            if k not in self.cols:\n",
    "                raise KeyError(\"Feature(column) not present in the Training Dataset\")\n",
    "                \n",
    "            if self.rv[k] == 'discrete':\n",
    "                try:\n",
    "                    store_val = self.store[k][v][class_val]\n",
    "                except:\n",
    "                    store_val = self.discrete_likelihood_cal(k,v,class_val)\n",
    "            else:\n",
    "                store_val = self.continuous_likelihood_cal(k,v,class_val)\n",
    "\n",
    "            val *= store_val\n",
    "                                         \n",
    "        return val\n",
    "    \n",
    "    def prior(self, class_val):\n",
    "        df = self.df\n",
    "        return len(df[df[self.c_n] == class_val])/df.shape[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        df = self.df\n",
    "        \n",
    "        if type(X) == pd.core.series.Series:\n",
    "            values_list = [list(X.items())]\n",
    "            \n",
    "        elif type(X) == pd.core.frame.DataFrame:\n",
    "            values_list = [list(y.items()) for x,y in X.iterrows()]\n",
    "            \n",
    "        else:\n",
    "            raise TypeError('{} is not supported type'.format(type(X)))\n",
    "            \n",
    "        \n",
    "        predictions_list = []\n",
    "        for values in values_list:\n",
    "            likelihood_priors = {}\n",
    "            for class_val in df[self.c_n].unique():\n",
    "                likelihood_priors[class_val] = self.prior(class_val)*self.likelihood_expr(class_val,values)\n",
    "            #print(likelihood_priors)\n",
    "            \n",
    "            normalizing_prob = np.sum([x for x in likelihood_priors.values()])\n",
    "            probabilities = [(y/normalizing_prob,x) for x,y in likelihood_priors.items()]\n",
    "            #print(probabilities)\n",
    "            \n",
    "            if len(probabilities) == 2:\n",
    "                # For 2 Class Predictions\n",
    "                max_prob = max(probabilities)[1]\n",
    "                predictions_list.append(max_prob)\n",
    "            \n",
    "            else:\n",
    "                # For Mulit Class Predictions\n",
    "                exp_1 = [np.exp(x) for x,y in probabilities]\n",
    "                exp_2 = np.sum(exp_1)\n",
    "                softmax = exp_1/exp_2\n",
    "                #print(softmax)\n",
    "                class_names = [y for x,y in probabilities]\n",
    "                softmax_values = [(x,y) for x,y in zip(softmax,class_names)]\n",
    "                #print(softmax_values)\n",
    "                max_prob = max(softmax_values)[1]\n",
    "                predictions_list.append(max_prob)\n",
    "        \n",
    "        \n",
    "        return predictions_list\n",
    "    \n",
    "    def accuracy_score(self, X, Y):\n",
    "        assert len(X) == len(Y), 'Given values are not equal in size'\n",
    "        \n",
    "        total_matching_values = [x == y for x,y in zip(X,Y)]\n",
    "        return (np.sum(total_matching_values)/len(total_matching_values))*100\n",
    "    \n",
    "    def calculate_confusion_matrix(self, X, Y):\n",
    "        df = self.df\n",
    "        \n",
    "        unique_class_values = df[self.c_n].unique()\n",
    "        decimal_class_values = list(range(len(unique_class_values)))\n",
    "        numerical = {x:y for x,y in zip(unique_class_values, decimal_class_values)}\n",
    "        \n",
    "        x = [numerical[x] for x in X]\n",
    "        y = [numerical[y] for y in Y]\n",
    "        \n",
    "        \n",
    "        n = len(decimal_class_values)\n",
    "        confusion_matrix = np.zeros((n,n))\n",
    "        \n",
    "        for i,j in zip(x,y):\n",
    "            if i == j:\n",
    "                confusion_matrix[i][i] += 1\n",
    "            elif i != j:\n",
    "                confusion_matrix[i][j] += 1\n",
    "        \n",
    "        return confusion_matrix\n",
    "            \n",
    "    \n",
    "    def precision_score(self, X, Y):\n",
    "        \"\"\"\n",
    "        Implemented Only for Binary Classes\n",
    "        \n",
    "        X -> y_true\n",
    "        Y -> y_pred\n",
    "        \"\"\"\n",
    "        assert len(X) == len(Y), 'Given values are not equal in size'\n",
    "        \n",
    "        confusion_matrix = self.calculate_confusion_matrix(X,Y)\n",
    "        tp = confusion_matrix[0][0]\n",
    "        fp = confusion_matrix[1][0]\n",
    "        \n",
    "        return tp / (tp+fp)\n",
    "    \n",
    "    def recall_score(self, X, Y):\n",
    "        \"\"\"\n",
    "        Implemented Only for Binary Classes\n",
    "        \n",
    "        X -> y_true\n",
    "        Y -> y_pred\n",
    "        \"\"\"\n",
    "        assert len(X) == len(Y), 'Given values are not equal in size'\n",
    "        \n",
    "        confusion_matrix = self.calculate_confusion_matrix(X,Y)\n",
    "        tp = confusion_matrix[0][0]\n",
    "        fn = confusion_matrix[0][1]\n",
    "        \n",
    "        return tp / (tp+fn)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "genx = NB(target='diagnosis',dataframe=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genx.likelihood_cal('cap-shape','x','e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genx.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(testing_data.iloc[:,0])\n",
    "y_pred = genx.predict(testing_data.iloc[:,1:])\n",
    "#print(y_test)\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score -> 93.706 %\n",
      "Precison Score -> 0.911\n",
      "Recall Score -> 0.891\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score -> {} %'.format(round(genx.accuracy_score(y_test,y_pred),3)))\n",
    "print('Precison Score -> {}'.format(round(genx.precision_score(y_test,y_pred),3)))\n",
    "print('Recall Score -> {}'.format(round(genx.recall_score(y_test,y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
