{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tumor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_data size -> (426, 33)\n",
      "Testing_data size -> (143, 33)\n"
     ]
    }
   ],
   "source": [
    "ind = list(data.index)\n",
    "np.random.shuffle(ind)\n",
    "\n",
    "train_len = int(data.shape[0]*0.75)\n",
    "train_ind = ind[:train_len]\n",
    "training_data = data.iloc[train_ind,:]\n",
    "#training_data.head()\n",
    "\n",
    "test_ind = ind[train_len:]\n",
    "testing_data = data.iloc[test_ind,:]\n",
    "#testing_data.head()\n",
    "\n",
    "print('Training_data size -> {}'.format(training_data.shape))\n",
    "print('Testing_data size -> {}'.format(testing_data.shape))\n",
    "\n",
    "assert data.shape[0] ==  len(train_ind)+ len(test_ind), 'Not equal distribution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashank/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "training_data.drop(columns=[data.columns[0],data.columns[-1]], inplace=True)\n",
    "testing_data.drop(columns=[data.columns[0],data.columns[-1]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>M</td>\n",
       "      <td>16.13</td>\n",
       "      <td>17.88</td>\n",
       "      <td>107.00</td>\n",
       "      <td>807.2</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.15590</td>\n",
       "      <td>0.13540</td>\n",
       "      <td>0.07752</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>...</td>\n",
       "      <td>20.21</td>\n",
       "      <td>27.26</td>\n",
       "      <td>132.70</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.14460</td>\n",
       "      <td>0.5804</td>\n",
       "      <td>0.5274</td>\n",
       "      <td>0.18640</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.12330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>14.93</td>\n",
       "      <td>70.67</td>\n",
       "      <td>372.7</td>\n",
       "      <td>0.07987</td>\n",
       "      <td>0.07079</td>\n",
       "      <td>0.03546</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>...</td>\n",
       "      <td>12.09</td>\n",
       "      <td>20.83</td>\n",
       "      <td>79.73</td>\n",
       "      <td>447.1</td>\n",
       "      <td>0.10950</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.1553</td>\n",
       "      <td>0.06754</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.07287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>B</td>\n",
       "      <td>15.04</td>\n",
       "      <td>16.74</td>\n",
       "      <td>98.73</td>\n",
       "      <td>689.4</td>\n",
       "      <td>0.09883</td>\n",
       "      <td>0.13640</td>\n",
       "      <td>0.07721</td>\n",
       "      <td>0.06142</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>...</td>\n",
       "      <td>16.76</td>\n",
       "      <td>20.43</td>\n",
       "      <td>109.70</td>\n",
       "      <td>856.9</td>\n",
       "      <td>0.11350</td>\n",
       "      <td>0.2176</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.08549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>B</td>\n",
       "      <td>13.69</td>\n",
       "      <td>16.07</td>\n",
       "      <td>87.84</td>\n",
       "      <td>579.1</td>\n",
       "      <td>0.08302</td>\n",
       "      <td>0.06374</td>\n",
       "      <td>0.02556</td>\n",
       "      <td>0.02031</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>...</td>\n",
       "      <td>14.84</td>\n",
       "      <td>20.21</td>\n",
       "      <td>99.16</td>\n",
       "      <td>670.6</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2096</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.06987</td>\n",
       "      <td>0.3323</td>\n",
       "      <td>0.07701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>B</td>\n",
       "      <td>13.74</td>\n",
       "      <td>17.91</td>\n",
       "      <td>88.12</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0.07944</td>\n",
       "      <td>0.06376</td>\n",
       "      <td>0.02881</td>\n",
       "      <td>0.01329</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>...</td>\n",
       "      <td>15.34</td>\n",
       "      <td>22.46</td>\n",
       "      <td>97.19</td>\n",
       "      <td>725.9</td>\n",
       "      <td>0.09711</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.1564</td>\n",
       "      <td>0.06019</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "34          M        16.13         17.88          107.00      807.2   \n",
       "381         B        11.04         14.93           70.67      372.7   \n",
       "500         B        15.04         16.74           98.73      689.4   \n",
       "374         B        13.69         16.07           87.84      579.1   \n",
       "149         B        13.74         17.91           88.12      585.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "34           0.10400           0.15590         0.13540              0.07752   \n",
       "381          0.07987           0.07079         0.03546              0.02074   \n",
       "500          0.09883           0.13640         0.07721              0.06142   \n",
       "374          0.08302           0.06374         0.02556              0.02031   \n",
       "149          0.07944           0.06376         0.02881              0.01329   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "34          0.1998  ...         20.21          27.26           132.70   \n",
       "381         0.2003  ...         12.09          20.83            79.73   \n",
       "500         0.1668  ...         16.76          20.43           109.70   \n",
       "374         0.1872  ...         14.84          20.21            99.16   \n",
       "149         0.1473  ...         15.34          22.46            97.19   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "34       1261.0           0.14460             0.5804           0.5274   \n",
       "381       447.1           0.10950             0.1982           0.1553   \n",
       "500       856.9           0.11350             0.2176           0.1856   \n",
       "374       670.6           0.11050             0.2096           0.1346   \n",
       "149       725.9           0.09711             0.1824           0.1564   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "34                0.18640          0.4270                  0.12330  \n",
       "381               0.06754          0.3202                  0.07287  \n",
       "500               0.10180          0.2177                  0.08549  \n",
       "374               0.06987          0.3323                  0.07701  \n",
       "149               0.06019          0.2350                  0.07014  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>M</td>\n",
       "      <td>18.03</td>\n",
       "      <td>16.85</td>\n",
       "      <td>117.50</td>\n",
       "      <td>990.0</td>\n",
       "      <td>0.08947</td>\n",
       "      <td>0.12320</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.062540</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>...</td>\n",
       "      <td>20.38</td>\n",
       "      <td>22.02</td>\n",
       "      <td>133.30</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>0.12630</td>\n",
       "      <td>0.26660</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.15350</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>0.08225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>B</td>\n",
       "      <td>12.62</td>\n",
       "      <td>17.15</td>\n",
       "      <td>80.62</td>\n",
       "      <td>492.9</td>\n",
       "      <td>0.08583</td>\n",
       "      <td>0.05430</td>\n",
       "      <td>0.029660</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>...</td>\n",
       "      <td>14.34</td>\n",
       "      <td>22.15</td>\n",
       "      <td>91.62</td>\n",
       "      <td>633.5</td>\n",
       "      <td>0.12250</td>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.09851</td>\n",
       "      <td>0.3270</td>\n",
       "      <td>0.07330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>M</td>\n",
       "      <td>17.08</td>\n",
       "      <td>27.15</td>\n",
       "      <td>111.20</td>\n",
       "      <td>930.9</td>\n",
       "      <td>0.09898</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.064310</td>\n",
       "      <td>0.1793</td>\n",
       "      <td>...</td>\n",
       "      <td>22.96</td>\n",
       "      <td>34.49</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>0.16000</td>\n",
       "      <td>0.24440</td>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.15550</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.09060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>B</td>\n",
       "      <td>11.33</td>\n",
       "      <td>14.16</td>\n",
       "      <td>71.79</td>\n",
       "      <td>396.6</td>\n",
       "      <td>0.09379</td>\n",
       "      <td>0.03872</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>...</td>\n",
       "      <td>12.20</td>\n",
       "      <td>18.99</td>\n",
       "      <td>77.37</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.12590</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.01111</td>\n",
       "      <td>0.2758</td>\n",
       "      <td>0.06386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>B</td>\n",
       "      <td>14.26</td>\n",
       "      <td>19.65</td>\n",
       "      <td>97.83</td>\n",
       "      <td>629.9</td>\n",
       "      <td>0.07837</td>\n",
       "      <td>0.22330</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.077980</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>...</td>\n",
       "      <td>15.30</td>\n",
       "      <td>23.73</td>\n",
       "      <td>107.00</td>\n",
       "      <td>709.0</td>\n",
       "      <td>0.08949</td>\n",
       "      <td>0.41930</td>\n",
       "      <td>0.678300</td>\n",
       "      <td>0.15050</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.10820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "444         M        18.03         16.85          117.50      990.0   \n",
       "454         B        12.62         17.15           80.62      492.9   \n",
       "460         M        17.08         27.15          111.20      930.9   \n",
       "276         B        11.33         14.16           71.79      396.6   \n",
       "112         B        14.26         19.65           97.83      629.9   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "444          0.08947           0.12320        0.109000             0.062540   \n",
       "454          0.08583           0.05430        0.029660             0.022720   \n",
       "460          0.09898           0.11100        0.100700             0.064310   \n",
       "276          0.09379           0.03872        0.001487             0.003333   \n",
       "112          0.07837           0.22330        0.300300             0.077980   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "444         0.1720  ...         20.38          22.02           133.30   \n",
       "454         0.1799  ...         14.34          22.15            91.62   \n",
       "460         0.1793  ...         22.96          34.49           152.10   \n",
       "276         0.1954  ...         12.20          18.99            77.37   \n",
       "112         0.1704  ...         15.30          23.73           107.00   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "444      1292.0           0.12630            0.26660         0.429000   \n",
       "454       633.5           0.12250            0.15170         0.188700   \n",
       "460      1648.0           0.16000            0.24440         0.263900   \n",
       "276       458.0           0.12590            0.07348         0.004955   \n",
       "112       709.0           0.08949            0.41930         0.678300   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "444               0.15350          0.2842                  0.08225  \n",
       "454               0.09851          0.3270                  0.07330  \n",
       "460               0.15550          0.3010                  0.09060  \n",
       "276               0.01111          0.2758                  0.06386  \n",
       "112               0.15050          0.2398                  0.10820  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(Cap-shape \\cap Cap-surface \\cap ......\\cap habitat | Class = p)\\\\[10pt]\n",
    "P(Cap-shape \\cap Cap-surface \\cap ......\\cap habitat | Class = e)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB:\n",
    "    def __init__(self, target, dataframe):\n",
    "        self.df = dataframe\n",
    "        # Target/Category Column\n",
    "        self.c_n = target\n",
    "        # Column Names\n",
    "        self.cols = list(self.df.columns)\n",
    "        self.cols.remove(self.c_n)\n",
    "        \n",
    "        # Determine Continuous or Discrete for each Columns\n",
    "        self.rv = {}\n",
    "        self.determine_rv_for_all()\n",
    "        \n",
    "        # Likelihoods of Discrete Random Variables\n",
    "        self.store = {}\n",
    "        self.discrete_likelihood_for_all()\n",
    "        \n",
    "        \n",
    "    def discrete_likelihood_cal(self, x, y, z):\n",
    "        \"\"\" \n",
    "        x -> Column Name (String)\n",
    "        y -> Column Value (String)\n",
    "        z -> Class value (String)\n",
    "        c_n -> Class Name (Target) # Not an Argument here #\n",
    "        \n",
    "        Returns -> P(x = y | c_n = z)\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        \n",
    "        if x not in self.cols:\n",
    "            raise KeyError(\"Feature(column) not present in the Training Dataset\")\n",
    "        \n",
    "        res = (1+len(df[(df[x] == y) & (df[self.c_n] == z)])) /(len(df[df[self.c_n] == z]) + len(df[x].unique()))\n",
    "        \n",
    "        \"\"\"if res == 0.0:\n",
    "            return 1/(len(df[df[self.c_n] == z]) + len(df[x].unique()))\"\"\"\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def discrete_likelihood_for_all(self):     \n",
    "        df = self.df\n",
    "        \n",
    "        discrete_cols = [x for x in self.cols if self.rv[x] == 'discrete']\n",
    "        \n",
    "        dict1 = {}\n",
    "        for x in discrete_cols:\n",
    "            dict2 = {}\n",
    "            for y in df[x].unique():\n",
    "                dict3 = {}\n",
    "                for z in df[self.c_n].unique():\n",
    "                    #print('P({}=\"{}\"|{}=\"{}\") = {}'.format(x,y,self.c_n,z,self.discrete_likelihood_cal(x, y, z)))\n",
    "                    dict3[z] = self.discrete_likelihood_cal(x, y, z)\n",
    "                dict2[y] = dict3\n",
    "            dict1[x] = dict2\n",
    "        \n",
    "        self.store = dict1\n",
    "        \n",
    "    def determine_rv(self, x):\n",
    "        \"\"\"\n",
    "        x -> Column Name\n",
    "        \"\"\"\n",
    "        df = self.df\n",
    "        \n",
    "        val = list(df[x])[0]\n",
    "        \n",
    "        if type(val) == str or (type(val) == int and len(df[x].unique()) < len(df[x])):\n",
    "            return 'discrete'\n",
    "        return 'continuous'\n",
    "    \n",
    "    def determine_rv_for_all(self):\n",
    "        \"\"\"\n",
    "        self.rv = {}\n",
    "        \"\"\"\n",
    "        \n",
    "        self.rv = {x:self.determine_rv(x) for x in self.cols}\n",
    "\n",
    "    def normal_pdf(self, sample, x=None):\n",
    "        mu = np.mean(sample)\n",
    "        sigma = np.std(sample)\n",
    "        if x == None:\n",
    "            x = sample\n",
    "\n",
    "        expr = np.exp((-1/2)*(((x-mu)/sigma)**2))/(np.sqrt(2*np.pi*sigma))\n",
    "        return expr\n",
    "\n",
    "    def continuous_likelihood_cal(self, column_name, column_val, class_val):\n",
    "        df = self.df\n",
    "        \n",
    "        sample = df[df[self.c_n] == class_val][column_name]\n",
    "\n",
    "        return self.normal_pdf(sample, column_val)\n",
    "    \n",
    "    def likelihood_expr(self, class_val, expr):\n",
    "        val = 1  \n",
    "        \n",
    "        for k,v in expr:\n",
    "            \n",
    "            if k not in self.cols:\n",
    "                raise KeyError(\"Feature(column) not present in the Training Dataset\")\n",
    "                \n",
    "            if self.rv[k] == 'discrete':\n",
    "                try:\n",
    "                    store_val = self.store[k][v][class_val]\n",
    "                except:\n",
    "                    store_val = self.discrete_likelihood_cal(k,v,class_val)\n",
    "            else:\n",
    "                store_val = self.continuous_likelihood_cal(k,v,class_val)\n",
    "\n",
    "            val *= store_val\n",
    "                                         \n",
    "        return val\n",
    "    \n",
    "    def prior(self, class_val):\n",
    "        df = self.df\n",
    "        return len(df[df[self.c_n] == class_val])/df.shape[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        df = self.df\n",
    "        \n",
    "        if type(X) == pd.core.series.Series:\n",
    "            values_list = [list(X.items())]\n",
    "            \n",
    "        elif type(X) == pd.core.frame.DataFrame:\n",
    "            values_list = [list(y.items()) for x,y in X.iterrows()]\n",
    "            \n",
    "        else:\n",
    "            raise TypeError('{} is not supported type'.format(type(X)))\n",
    "            \n",
    "        \n",
    "        predictions_list = []\n",
    "        for values in values_list:\n",
    "            likelihood_priors = {}\n",
    "            for class_val in df[self.c_n].unique():\n",
    "                likelihood_priors[class_val] = self.prior(class_val)*self.likelihood_expr(class_val,values)\n",
    "            #print(likelihood_priors)\n",
    "            \n",
    "            normalizing_prob = np.sum([x for x in likelihood_priors.values()])\n",
    "            probabilities = [(y/normalizing_prob,x) for x,y in likelihood_priors.items()]\n",
    "            #print(probabilities)\n",
    "            \n",
    "            if len(probabilities) == 2:\n",
    "                # For 2 Class Predictions\n",
    "                max_prob = max(probabilities)[1]\n",
    "                predictions_list.append(max_prob)\n",
    "            \n",
    "            else:\n",
    "                # For Mulit Class Predictions\n",
    "                exp_1 = [np.exp(x) for x,y in probabilities]\n",
    "                exp_2 = np.sum(exp_1)\n",
    "                softmax = exp_1/exp_2\n",
    "                #print(softmax)\n",
    "                class_names = [y for x,y in probabilities]\n",
    "                softmax_values = [(x,y) for x,y in zip(softmax,class_names)]\n",
    "                #print(softmax_values)\n",
    "                max_prob = max(softmax_values)[1]\n",
    "                predictions_list.append(max_prob)\n",
    "        \n",
    "        \n",
    "        return predictions_list\n",
    "    \n",
    "    def accuracy_score(self, X, Y):\n",
    "        assert len(X) == len(Y), 'Given values are not equal in size'\n",
    "        \n",
    "        total_matching_values = [x == y for x,y in zip(X,Y)]\n",
    "        return (np.sum(total_matching_values)/len(total_matching_values))*100\n",
    "    \n",
    "    def calculate_confusion_matrix(self, X, Y):\n",
    "        df = self.df\n",
    "        \n",
    "        unique_class_values = df[self.c_n].unique()\n",
    "        decimal_class_values = list(range(len(unique_class_values)))\n",
    "        numerical = {x:y for x,y in zip(unique_class_values, decimal_class_values)}\n",
    "        \n",
    "        x = [numerical[x] for x in X]\n",
    "        y = [numerical[y] for y in Y]\n",
    "        \n",
    "        \n",
    "        n = len(decimal_class_values)\n",
    "        confusion_matrix = np.zeros((n,n))\n",
    "        \n",
    "        for i,j in zip(x,y):\n",
    "            if i == j:\n",
    "                confusion_matrix[i][i] += 1\n",
    "            elif i != j:\n",
    "                confusion_matrix[i][j] += 1\n",
    "        \n",
    "        return confusion_matrix\n",
    "            \n",
    "    \n",
    "    def precision_score(self, X, Y):\n",
    "        \"\"\"\n",
    "        Implemented Only for Binary Classes\n",
    "        \n",
    "        X -> y_true\n",
    "        Y -> y_pred\n",
    "        \"\"\"\n",
    "        assert len(X) == len(Y), 'Given values are not equal in size'\n",
    "        \n",
    "        confusion_matrix = self.calculate_confusion_matrix(X,Y)\n",
    "        tp = confusion_matrix[0][0]\n",
    "        fp = confusion_matrix[1][0]\n",
    "        \n",
    "        return tp / (tp+fp)\n",
    "    \n",
    "    def recall_score(self, X, Y):\n",
    "        \"\"\"\n",
    "        Implemented Only for Binary Classes\n",
    "        \n",
    "        X -> y_true\n",
    "        Y -> y_pred\n",
    "        \"\"\"\n",
    "        assert len(X) == len(Y), 'Given values are not equal in size'\n",
    "        \n",
    "        confusion_matrix = self.calculate_confusion_matrix(X,Y)\n",
    "        tp = confusion_matrix[0][0]\n",
    "        fn = confusion_matrix[0][1]\n",
    "        \n",
    "        return tp / (tp+fn)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "genx = NB(target='diagnosis',dataframe=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genx.likelihood_cal('cap-shape','x','e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genx.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(testing_data.iloc[:,0])\n",
    "y_pred = genx.predict(testing_data.iloc[:,1:])\n",
    "#print(y_test)\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score -> 92.308 %\n",
      "Precison Score -> 0.908\n",
      "Recall Score -> 0.922\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score -> {} %'.format(round(genx.accuracy_score(y_test,y_pred),3)))\n",
    "print('Precison Score -> {}'.format(round(genx.precision_score(y_test,y_pred),3)))\n",
    "print('Recall Score -> {}'.format(round(genx.recall_score(y_test,y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
